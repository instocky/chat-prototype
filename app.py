import streamlit as st
from langchain_core.runnables import RunnableWithMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from dotenv import load_dotenv
import os
from llm_providers import get_provider  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à—É —Ñ–∞–±—Ä–∏–∫—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

load_dotenv()

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
SYSTEM_PROMPT = """–¢—ã - –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ —É–º–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. 
–¢–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –≤—Å–µ–≥–¥–∞ —á–µ—Ç–∫–∏–µ –∏ –ø–æ –¥–µ–ª—É.
–ï—Å–ª–∏ —Ç–µ–±–µ –∑–∞–¥–∞—é—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å - —Ç—ã –¥–∞–µ—à—å –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞.
–ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç - —á–µ—Å—Ç–Ω–æ –≥–æ–≤–æ—Ä–∏—à—å –æ–± —ç—Ç–æ–º.
"""

def initialize_chat(provider_name: str, model_name: str):
    # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    api_key_map = {
        "groq": "GROQ_API_KEY",
        "cerebras": "CEREBRAS_API_KEY"
    }
    
    # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ–≥–æ –Ω–∞–ª–∏—á–∏–µ
    api_key = os.getenv(api_key_map[provider_name])
    if not api_key:
        raise ValueError(f"API key for {provider_name} not found in environment variables")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏ —Å–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    provider = get_provider(provider_name, api_key)
    chat = provider.create_model(
        model_name=model_name,
        temperature=0.7,
        max_tokens=4096
    )
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ChatPromptTemplate
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=SYSTEM_PROMPT),  # –Ø–≤–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}")
    ])
    
    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RunnableWithMessageHistory
    chain = prompt | chat
    
    return chain

def get_message_history():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ LangChain"""
    history = []
    for msg in st.session_state.get("messages", []):
        if msg["role"] == "user":
            history.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            history.append(AIMessage(content=msg["content"]))
    return history

def main():
    st.title("ü§ñ –ß–∞—Ç-–±–æ—Ç –ø—Ä–æ—Ç–æ—Ç–∏–ø")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö API –∫–ª—é—á–µ–π
    for env_var in ["GROQ_API_KEY", "CEREBRAS_API_KEY"]:
        if not os.getenv(env_var):
            st.error(f"–û—à–∏–±–∫–∞: {env_var} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
            return
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏
    providers = {
        "groq": ["mixtral-8x7b-32768", "llama-3.1-70b-versatile"],
        "cerebras": ["llama3.1-8b", "llama3.1-70b"]
    }
    
    # –°–µ–ª–µ–∫—Ç–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –≤ —Å–∞–π–¥–±–∞—Ä–µ
    provider_name = st.sidebar.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞:",
        list(providers.keys())
    )
    
    # –°–µ–ª–µ–∫—Ç–æ—Ä –º–æ–¥–µ–ª–∏ –≤ —Å–∞–π–¥–±–∞—Ä–µ
    model_name = st.sidebar.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
        providers[provider_name]
    )
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–ª–∏ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é –ø—Ä–∏ —Å–º–µ–Ω–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞/–º–æ–¥–µ–ª–∏
    if ("chain" not in st.session_state or 
        st.session_state.get("current_provider") != provider_name or
        st.session_state.get("current_model") != model_name):
        
        st.session_state.chain = initialize_chat(provider_name, model_name)
        st.session_state.current_provider = provider_name
        st.session_state.current_model = model_name
        st.session_state.messages = []
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # –ü–æ–ª–µ –≤–≤–æ–¥–∞
    if prompt := st.chat_input("–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ..."):
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
            
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –±–æ—Ç–∞
        with st.chat_message("assistant"):
            response = st.session_state.chain.invoke(
                {"input": prompt, "history": get_message_history()}
            )
            content = response.content if hasattr(response, 'content') else str(response)
            st.markdown(content)
            st.session_state.messages.append({"role": "assistant", "content": content})

if __name__ == "__main__":
    main()