import streamlit as st
from langchain_groq import ChatGroq
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from dotenv import load_dotenv
import os

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

def initialize_chat():
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
    chat = ChatGroq(
        groq_api_key=os.getenv('GROQ_API_KEY'),
        model_name="mixtral-8x7b-32768"
    )
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞–º—è—Ç—å
    memory = ConversationBufferMemory()
    
    # –°–æ–∑–¥–∞—ë–º —Ü–µ–ø–æ—á–∫—É —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
    conversation = ConversationChain(
        llm=chat,
        memory=memory,
        verbose=True
    )
    
    return conversation

def main():
    st.title("ü§ñ –ß–∞—Ç-–±–æ—Ç –ø—Ä–æ—Ç–æ—Ç–∏–ø")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é
    if "conversation" not in st.session_state:
        st.session_state.conversation = initialize_chat()
    
    # –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # –ü–æ–ª–µ –≤–≤–æ–¥–∞
    if prompt := st.chat_input("–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ..."):
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
            
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –±–æ—Ç–∞
        with st.chat_message("assistant"):
            response = st.session_state.conversation.predict(input=prompt)
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()